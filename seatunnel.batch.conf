
env {
  job.mode = BATCH
  job.name = "SeaTunnel"
  spark.executor.instances = 1
  spark.executor.cores = 1
  spark.executor.memory = "1g"
  spark.master = local
}

source {
  FakeSource {
    parallelism = 2
    result_table_name = "fake"
    row.num = 16
    schema = {
      fields {
        name = "string"
        age = "int"
      }
    }
  }
}

sink {
  jdbc {
    url = "jdbc:snowflake://oatgglz-oib25027.snowflakecomputing.com"
    driver = "net.snowflake.client.jdbc.SnowflakeDriver"
    user = "PUBLIC_USER"
    password = "9o7REqB2gtqs9e6"
    query = "insert into odsc.public.fake_table(name,age) values(?,?)"
  }
}
